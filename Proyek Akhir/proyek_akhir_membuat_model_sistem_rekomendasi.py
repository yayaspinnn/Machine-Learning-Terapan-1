# -*- coding: utf-8 -*-
"""Proyek Akhir: Membuat Model Sistem Rekomendasi.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zJ33jIqEd__A9miZMVx7J7fE-O4xtvJ-

https://www.kaggle.com/datasets/whenamancodes/amazon-reviews-on-women-dresses

Amazon Reviews on Women Dresses

## Mengunduh Data
"""

! pip install -q kaggle

from google.colab import files

files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!ls ~/.kaggle

!kaggle datasets download -d thedevastator/skincare-products-that-perform-the-best-at-sepho

!mkdir skincare-products-that-perform-the-best-at-sephosses
!unzip skincare-products-that-perform-the-best-at-sepho.zip -d skincare-products-that-perform-the-best-at-sepho
!ls skincare-products-that-perform-the-best-at-sepho

"""## Mepersiapkan Data"""

#Importing the Libraries
import numpy as np
import pandas as pd
import datetime
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn import metrics

import warnings
import sys
if not sys.warnoptions:
    warnings.simplefilter("ignore")
np.random.seed(42)
from functools import reduce
pd.set_option('display.max_columns', None)

dataset = pd.read_csv('/content/skincare-products-that-perform-the-best-at-sepho/eyecare.csv')

dataset

dataset.info()

"""## Membersihkan Data

### Memilih FItur
"""

dataset.rename(columns = {'Unnamed: 0':'user_id'}, inplace = True)
selected_df = dataset[['user_id', 'brand', 'name', 'review_score']]

clean_df = selected_df.dropna()

clean_df.info()

clean_df.head()

"""### Format Ulang Fitur"""

len(clean_df.user_id.unique())

clean_df['review_score'] = round(clean_df['review_score'])
clean_df

clean_df.info()

"""### Membuat Fitur ID Produk"""

LE = LabelEncoder()

clean_df['product_id'] = LE.fit_transform(clean_df['name'])

clean_df

for col in clean_df:
    print(f"\033[1m{col} \n{20 * '-'}\033[0m")
    print(clean_df[col].value_counts(), '\n')

"""## Model Development dengan Content Based Filtering"""

product_id = clean_df['product_id'].tolist()
 
brand = clean_df['brand'].tolist()
 
name = clean_df['name'].tolist()
 
print(len(product_id))
print(len(brand))
print(len(name))

product_new = pd.DataFrame({
    'product_id': product_id,
    'name': name,
    'brand': brand
})
product_new

first_df = product_new
first_df.sample(5)

"""### TF-IDF Vectorizer"""

from sklearn.feature_extraction.text import TfidfVectorizer

tf = TfidfVectorizer()
tf.fit(first_df['brand']) 
tf.get_feature_names()

tfidf_matrix = tf.fit_transform(first_df['brand']) 
 
tfidf_matrix.shape

tfidf_matrix.todense()

pd.DataFrame(
    tfidf_matrix.todense(), 
    columns=tf.get_feature_names(),
    index=first_df.name
).sample(22, axis=1).sample(10, axis=0)

"""### Cosine Similarity"""

from sklearn.metrics.pairwise import cosine_similarity
 
cosine_sim = cosine_similarity(tfidf_matrix) 
cosine_sim

cosine_sim_df = pd.DataFrame(cosine_sim, index=first_df['name'], columns=first_df['name'])
print('Shape:', cosine_sim_df.shape)
 
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""### Mendapatkan Rekomendasi"""

def resto_recommendations(nama_resto, similarity_data=cosine_sim_df, items=first_df[['name', 'brand']], k=5):
    index = similarity_data.loc[:,nama_resto].to_numpy().argpartition(
        range(-1, -k, -1))
    
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    
    closest = closest.drop(nama_resto, errors='ignore')
 
    return pd.DataFrame(closest).merge(items).head(k)

first_df[first_df.name.eq('I-Waken Eye Serum')]

resto_recommendations('I-Waken Eye Serum')

"""## Model Development dengan Collaborative Filtering"""

user_id = clean_df['user_id'].tolist()
 
product_id = clean_df['product_id'].tolist()

rating = clean_df['review_score'].tolist()
 
print(len(user_id))
print(len(product_id))
print(len(rating))

rating_new = pd.DataFrame({
    'user_id': user_id,
    'product_id' : product_id,
    'rating': rating
})
rating_new

second_df = rating_new
second_df.sample(5)

"""### Mempersiapkan Data"""

user_ids = second_df['user_id'].unique().tolist()
print('list user_id: ', user_ids)
 
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded user_id : ', user_to_user_encoded)
 
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke user_id: ', user_encoded_to_user)

eyecare_ids = second_df['product_id'].unique().tolist()
 
eyecare_to_eyecare_encoded = {x: i for i, x in enumerate(eyecare_ids)}
 
eyecare_encoded_to_eyecare = {i: x for i, x in enumerate(eyecare_ids)}

second_df['user'] = second_df['user_id'].map(user_to_user_encoded)

second_df['product'] = second_df['product_id'].map(eyecare_to_eyecare_encoded)

num_users = len(user_to_user_encoded)
print(num_users)
 
num_eyecare = len(eyecare_to_eyecare_encoded)
print(num_eyecare)
 
min_rating = min(second_df['rating'])
 
max_rating = max(second_df['rating'])
 
print('Number of User: {}, Number of Skincare: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_eyecare, min_rating, max_rating
))

"""### Membagi Data untuk Training dan Validasi"""

second_df = second_df.sample(frac=1, random_state=42)
second_df

x = second_df[['user','product']].values
 
y = second_df['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values
 
train_indices = int(0.8 * second_df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)
 
print(x, y)

"""### Proses Training"""

from zipfile import ZipFile
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path

class RecommenderNet(tf.keras.Model):
 
  def __init__(self, num_users, num_eyecare, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_eyecare = num_eyecare
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding(
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1)
    self.eyecare_embedding = layers.Embedding(
        num_eyecare,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.eyecare_bias = layers.Embedding(num_eyecare, 1)
 
  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0])
    user_bias = self.user_bias(inputs[:, 0]) 
    eyecare_vector = self.eyecare_embedding(inputs[:, 1])
    eyecare_bias = self.eyecare_bias(inputs[:, 1])
 
    dot_user_eyecare = tf.tensordot(user_vector, eyecare_vector, 2) 
 
    x = dot_user_eyecare + user_bias + eyecare_bias
    
    return tf.nn.sigmoid(x)

model = RecommenderNet(num_users, num_eyecare, 50)
 
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 8,
    epochs = 100,
    validation_data = (x_val, y_val)
)

"""### Visualisasi Metrik"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""### Mendapatkan Rekomendasi Eyecare"""

eyecare_df = product_new
rating_df = rating_new
 
user_id = rating_df['user_id'].sample(1).iloc[0]
eyecare_visited_by_user = rating_df[rating_df['product_id'] == user_id]
 
eyecare_not_visited = eyecare_df[~eyecare_df['product_id'].isin(eyecare_visited_by_user['product_id'].values)]['product_id'] 
eyecare_not_visited = list(
    set(eyecare_not_visited)
    .intersection(set(eyecare_to_eyecare_encoded.keys()))
)
 
eyecare_not_visited = [[eyecare_to_eyecare_encoded.get(x)] for x in eyecare_not_visited]
user_encoder = eyecare_to_eyecare_encoded.get(user_id)
user_eyecare_array = np.hstack(
    ([[user_encoder]] * len(eyecare_not_visited), eyecare_not_visited)
)

ratings = model.predict(user_eyecare_array).flatten()
 
top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_eyecare_ids = [
    eyecare_encoded_to_eyecare.get(eyecare_not_visited[x][0]) for x in top_ratings_indices
]
 
print('Showing recommendations for users: {}'.format(user_id))
print('======' * 9)
print('Eyecare with high ratings from user')
print('--------' * 8)
 
top_eyecare_user = (
    eyecare_visited_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .product_id.values
)
 
eyecare_df_rows = eyecare_df[eyecare_df['product_id'].isin(top_eyecare_user)]
for row in eyecare_df_rows.itertuples():
    print(row.name, ':', row.brand)
 
print('--------' * 8)
print('Top 10 resto recommendation')
print('--------' * 8)
 
recommended_eyecare = eyecare_df[eyecare_df['product_id'].isin(recommended_eyecare_ids)]
for row in recommended_eyecare.itertuples():
    print(row.name, ':', row.brand)